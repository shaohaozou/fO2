import pandas as pd
import numpy as np

from sklearn.ensemble import ExtraTreesRegressor

from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RepeatedKFold

import data_process

import joblib

import time


df1 = pd.read_csv("Appendix 2.csv", encoding='cp1252')

df = data_process.pca_process(df1)


X = df.iloc[:, -7:]
y = df['log fO2 (dFMQ)']

param_grid = {
    'n_estimators': [int(x) for x in np.arange(start = 100, stop = 2100, step = 100)],
    'criterion': ['squared_error', 'absolute_error'],
    'max_depth': [2,8,16,32,50],
    #'min_sample_split': [int(i)  for i in np.arange(2, 8, 1)],
    #'min_sample_leaf': [i for i in range(1,7)],
    #'oob_score': [True, False],
    #'max_features': ['auto','sqrt','log2'],    
    'bootstrap': [True, False],
    'warm_start': [True, False],
}


ETs_Model = ExtraTreesRegressor()

cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1)

Grid_Search = GridSearchCV(ETs_Model, param_grid, scoring="r2", cv = cv, n_jobs = -1)

GridSearchResults=Grid_Search.fit(X,y)

# Fetching the best hyperparameters
#print(GridSearchResults.best_params_)
#print(GridSearchResults.best_score_)
#print("ETs_Model in $.3f s" % t1)

joblib.dump(GridSearchResults.best_params_, 'best_ETs.pkl', compress =1)